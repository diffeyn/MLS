{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295286d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032740bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--force-device-scale-factor=1\")\n",
    "\n",
    "    # Look human\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    options.add_argument(\n",
    "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    \"source\": \"Object.defineProperty(navigator,'webdriver',{get:()=>undefined})\"\n",
    "    })\n",
    "    \n",
    "    return driver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feed(driver, link, match_id):\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    driver.get(link)\n",
    "    feed = []\n",
    "    \n",
    "    try:\n",
    "        feed_button = driver.find_element(By.XPATH,\n",
    "                            \"//*[normalize-space(text())='Feed']\")\n",
    "\n",
    "        feed_button.click()\n",
    "        \n",
    "        utils.js_scroll_by(driver, 900)\n",
    "\n",
    "        utils.js_scroll_by(driver, 3000)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, \"//*[normalize-space(text())='First half begins.']\")))\n",
    "\n",
    "        first_half = driver.find_element(By.XPATH, \"//*[normalize-space(text())='First half begins.']\")\n",
    "\n",
    "        utils.js_scroll_into_view(driver, first_half)\n",
    "        if not first_half:\n",
    "            print(f\"First half element not found for link {link}\")\n",
    "        try:            \n",
    "            cont = driver.find_element(By.CSS_SELECTOR, 'div[class=\"mls-o-match-feed\"]')\n",
    "\n",
    "            events = cont.find_elements(By.CSS_SELECTOR, 'div[class=\"mls-o-match-feed__container\"]')\n",
    "\n",
    "            for event in events:\n",
    "                minute_el = event.find_elements(By.CSS_SELECTOR, \".mls-o-match-summary__regular-time\")\n",
    "                minute = minute_el[0].text.strip() if minute_el else None\n",
    "\n",
    "                title_el = event.find_elements(By.CSS_SELECTOR, \".mls-o-match-feed__title\")\n",
    "                title = title_el[0].text.strip() if title_el else None\n",
    "\n",
    "                comment_el = event.find_elements(By.CSS_SELECTOR, \".mls-o-match-feed__comment\")\n",
    "                comment = comment_el[0].text.strip() if comment_el else None\n",
    "                \n",
    "                players_wrap = event.find_elements(By.XPATH, \".//*[contains(@class,'mls-o-match-feed__players')]\")\n",
    "\n",
    "                out_player = None\n",
    "                in_player = None\n",
    "\n",
    "                if players_wrap:\n",
    "                    out_nodes = players_wrap[0].find_elements(\n",
    "                        By.CSS_SELECTOR, \".mls-o-match-feed__sub-out .mls-o-match-feed__player\"\n",
    "                    )\n",
    "                    in_nodes = players_wrap[0].find_elements(\n",
    "                        By.CSS_SELECTOR, \".mls-o-match-feed__sub-in .mls-o-match-feed__player\"\n",
    "                    )\n",
    "\n",
    "                    out_player = out_nodes[0].text.strip() if out_nodes and out_nodes[0].text.strip() else None\n",
    "                    in_player  = in_nodes[0].text.strip()  if in_nodes and in_nodes[0].text.strip()  else None\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                feed.append({\n",
    "                    'match_id': match_id,\n",
    "                    'minute': minute,\n",
    "                    'title': title,\n",
    "                    'comment': comment,\n",
    "                    'out_player': out_player,\n",
    "                    'in_player': in_player\n",
    "                })\n",
    "                if not feed:\n",
    "                    print(f\"No feed events found for link {link}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting feed events for link {link}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting feed for link {link}: {e}\")\n",
    "    return feed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stats(driver, link, match_id):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    \n",
    "    driver.get(link)\n",
    "    \n",
    "    general_stats = []\n",
    "    shooting_stats = []\n",
    "    passing_stats = []\n",
    "    possession_stats = []\n",
    "    xg_stats = []\n",
    "    \n",
    "    main_body = driver.find_element(By.TAG_NAME, 'main')\n",
    "    stats_bttn = main_body.find_element(By.LINK_TEXT, 'Stats')\n",
    "\n",
    "    try:\n",
    "        stats_bttn.click()\n",
    "\n",
    "        try:\n",
    "            general_cont = wait.until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.XPATH,\n",
    "                    '//section[contains(@class,\"mls-l-module--stats-comparison\")'\n",
    "                    ' and contains(@class,\"mls-l-module--general\")'\n",
    "                    ' and not(contains(@style,\"display: none\"))]')))\n",
    "\n",
    "\n",
    "            utils.js_scroll_into_view(driver, general_cont)\n",
    "            general_cards = utils.scrape_cards(general_cont, driver)\n",
    "\n",
    "            for it in general_cards:\n",
    "                general_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping general stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            clubs_wrap = wait.until(\n",
    "                EC.visibility_of_element_located((\n",
    "                    By.XPATH,\n",
    "                    '//section[contains(@class,\"d3-l-section-row\")][@data-toggle=\"clubs\" and not(contains(@style,\"display: none\"))]'\n",
    "                )))\n",
    "\n",
    "            shooting_cont = clubs_wrap.find_element(\n",
    "                By.XPATH,\n",
    "                './/section[contains(@class,\"mls-l-module--shooting-breakdown\")]'\n",
    "            )\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView({block:'center'});\",\n",
    "                shooting_cont)\n",
    "\n",
    "            shooting_cards = utils.scrape_cards(shooting_cont, driver)\n",
    "\n",
    "            for it in shooting_cards:\n",
    "                shooting_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping shooting stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            passing_cont = driver.find_element(By.XPATH, '//section[contains(@class,\"passing-breakdown\")]')\n",
    "\n",
    "            passing_cards = utils.scrape_cards(passing_cont, driver)\n",
    "            for it in passing_cards:\n",
    "                passing_stats.append({\n",
    "                    'stat_name': it['stat'],\n",
    "                    'home_value': it['first'],\n",
    "                    'away_value': it['second']\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping passing stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            possession_cont = driver.find_element(By.XPATH, '//section[contains(@class,\"--possession\")]')\n",
    "            bar_cont = possession_cont.find_element(By.XPATH, './/*[contains(@class,\"mls-o-possession__intervals\")]')\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView({block:'center'});\",\n",
    "                bar_cont)\n",
    "\n",
    "\n",
    "            for bar in bar_cont.find_elements(By.XPATH, './/div[contains(@class,\"mls-o-possession__average-intervals\")]'):\n",
    "                tip_id = bar.get_attribute('data-for')\n",
    "\n",
    "                tooltips = bar.find_elements(By.XPATH, './/div[contains(@class,\"__react_component_tooltip\")]')\n",
    "\n",
    "                tip = wait.until(EC.presence_of_element_located((By.ID, tip_id)))\n",
    "\n",
    "                spans = tip.find_elements(By.XPATH, './/span')\n",
    "\n",
    "                texts = [s.get_attribute('textContent').strip() for s in spans]\n",
    "                texts = [t for t in texts if t and t.upper() != 'SKIP TO MAIN CONTENT']\n",
    "\n",
    "                if len(texts) >= 4:\n",
    "                    home_poss, home_adv, away_poss, away_adv = texts[:4]\n",
    "                else:\n",
    "                    home_poss = home_adv = away_poss = away_adv = None\n",
    "\n",
    "                possession_stats.append({\n",
    "                    'tip_id': tip_id,\n",
    "                    'home_possession': home_poss,\n",
    "                    'home_advantage': home_adv,\n",
    "                    'away_possession': away_poss,\n",
    "                    'away_advantage': away_adv\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping possession stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            xg_mod_xpath = (\n",
    "                '//section[@data-toggle=\"clubs\" and not(contains(@style,\"display: none\"))]'\n",
    "                '//section[contains(@class,\"mls-l-module--expected-goals\")]'\n",
    "            )\n",
    "            xg_mod = wait.until(EC.visibility_of_element_located((By.XPATH, xg_mod_xpath)))\n",
    "\n",
    "            groups = xg_mod.find_elements(\n",
    "                By.CSS_SELECTOR,\n",
    "                '.mls-o-expected-goals__chart-group, .mls-o-expected-goals__club-group'\n",
    "            )\n",
    "            chart_group = next(\n",
    "                (g for g in groups if 'mls-o-expected-goals__chart-group' in (g.get_attribute('class') or '')),\n",
    "                None\n",
    "            )\n",
    "            if chart_group is None:\n",
    "                raise Exception(\"xG chart-group not found\")\n",
    "\n",
    "            # ensure cards exist\n",
    "            wait.until(lambda d: any(\n",
    "                e.is_displayed() for e in chart_group.find_elements(By.CSS_SELECTOR, '.mls-o-stat-chart')\n",
    "            ))\n",
    "\n",
    "            for card in chart_group.find_elements(By.CSS_SELECTOR, '.mls-o-stat-chart'):\n",
    "                header = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__header')\n",
    "                first  = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__first-value')\n",
    "                second = card.find_element(By.CSS_SELECTOR,  '.mls-o-stat-chart__second-value')\n",
    "\n",
    "                stat_name  = (header.text or header.get_attribute('textContent') or '').strip()\n",
    "                home_value = (first.text  or first.get_attribute('textContent')  or '').strip()\n",
    "                away_value = (second.text or second.get_attribute('textContent') or '').strip()\n",
    "\n",
    "                xg_stats.append({\n",
    "                    'stat_name': stat_name,\n",
    "                    'home_value': home_value,\n",
    "                    'away_value': away_value\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping expected goals stats: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while scraping stats: {e}\")\n",
    "        pass\n",
    "\n",
    "    player_rows = []\n",
    "    gk_rows = []\n",
    "\n",
    "    try:\n",
    "        utils.js_scroll_by(driver, -3000)\n",
    "\n",
    "        player_btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '.mls-o-buttons__segment[value=\"players\"]')))\n",
    "        player_btn.click()\n",
    "\n",
    "\n",
    "        players_mod = wait.until(EC.visibility_of_element_located((\n",
    "            By.XPATH,\n",
    "            '//section[contains(@class,\"mls-l-module--match-hub-player-stats\") and not(contains(@style,\"display: none\"))]'\n",
    "        )))\n",
    "\n",
    "        utils.js_scroll_into_view(driver, players_mod)\n",
    "\n",
    "        club_blocks = players_mod.find_elements(By.CSS_SELECTOR, '.mls-c-stats--match-hub-player-stats')\n",
    "\n",
    "        for idx, block in enumerate(club_blocks):\n",
    "            side = 'home' if idx == 0 else 'away'\n",
    "            club_abbrev_el = block.find_elements(By.CSS_SELECTOR, '.mls-c-stats__club-abbreviation')\n",
    "            club_abbrev = club_abbrev_el[0].text.strip() if club_abbrev_el else None\n",
    "\n",
    "            for tbl in block.find_elements(By.CSS_SELECTOR, 'table.mls-o-table'):\n",
    "                cls = (tbl.get_attribute('class') or '').lower()\n",
    "                is_gk = 'goalkeeper' in cls\n",
    "\n",
    "                header_cells = tbl.find_elements(\n",
    "                    By.CSS_SELECTOR,\n",
    "                    'thead .mls-o-table__header-group:not(.mls-o-table__header-group--main) .mls-o-table__header'\n",
    "                )\n",
    "                if not header_cells:\n",
    "                    header_cells = tbl.find_elements(By.CSS_SELECTOR, 'thead .mls-o-table__header')\n",
    "\n",
    "                headers = [(h.text or h.get_attribute('textContent') or '').strip() for h in header_cells]\n",
    "\n",
    "                for tr in tbl.find_elements(By.CSS_SELECTOR, 'tbody .mls-o-table__row'):\n",
    "                    cells = tr.find_elements(By.CSS_SELECTOR, '.mls-o-table__cell')\n",
    "                    values = [(c.text or c.get_attribute('textContent') or '').strip() for c in cells]\n",
    "\n",
    "                    if len(values) < len(headers):\n",
    "                        values += [''] * (len(headers) - len(values))\n",
    "                    elif len(values) > len(headers):\n",
    "                        values = values[:len(headers)]\n",
    "\n",
    "                    row = dict(zip(headers, values))\n",
    "                    row.update({\n",
    "                        'match_id': match_id,\n",
    "                        'side': side,\n",
    "                        'club': club_abbrev\n",
    "                    })\n",
    "\n",
    "                    if is_gk:\n",
    "                        gk_rows.append(row)\n",
    "                    else:\n",
    "                        player_rows.append(row)\n",
    "\n",
    "                    combined_rows = player_rows + gk_rows\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while scraping player stats: {e}\")\n",
    "        \n",
    "    general_stats_df = pd.DataFrame(general_stats);  general_stats_df[\"category\"] = \"general\"\n",
    "    shooting_stats_df = pd.DataFrame(shooting_stats); shooting_stats_df[\"category\"] = \"shooting\"\n",
    "    passing_stats_df = pd.DataFrame(passing_stats);   passing_stats_df[\"category\"] = \"passing\"\n",
    "    possession_stats_df = pd.DataFrame(possession_stats); possession_stats_df[\"category\"] = \"possession\"\n",
    "    expected_goals_stats_df = pd.DataFrame(xg_stats); expected_goals_stats_df[\"category\"] = \"xg\"\n",
    "    player_stats_df = pd.DataFrame(combined_rows)\n",
    "\n",
    "    all_stats = pd.concat(\n",
    "        [general_stats_df, shooting_stats_df, passing_stats_df, possession_stats_df, expected_goals_stats_df],\n",
    "        axis=0, ignore_index=True\n",
    "    )\n",
    "\n",
    "    player_stats_df['match_id'] = match_id\n",
    "    all_stats['match_id'] = match_id\n",
    "    return all_stats, player_stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_match_id(obj, match_id):\n",
    "    if obj is None:\n",
    "        return pd.DataFrame({'match_id': [match_id]})\n",
    "\n",
    "    df = obj.copy() if isinstance(obj, pd.DataFrame) else pd.DataFrame(obj)\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.DataFrame({'match_id': [match_id]})\n",
    "\n",
    "    if 'match_id' in df.columns:\n",
    "        return df\n",
    "\n",
    "    df.insert(0, 'match_id', match_id)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_match_data(links, driver):\n",
    "\n",
    "    latest_stats = []\n",
    "    latest_player_stats = []\n",
    "    latest_feed = []\n",
    "\n",
    "    for link in links:\n",
    "        if (link is None or (isinstance(link, float) and math.isnan(link))\n",
    "                or str(link).strip() == '' or str(link).strip().lower() == 'nan'):\n",
    "            print(f\"[skip] bad link: {link!r}\")\n",
    "            continue\n",
    "        \n",
    "        raw_id = link.rstrip('/').split('/')[-1].split('?')[0]\n",
    "        match_id = hashlib.md5(raw_id.encode()).hexdigest()[:8]\n",
    "\n",
    "        feed = extract_feed(driver, link, match_id)\n",
    "        feed = add_match_id(feed, match_id)\n",
    "\n",
    "        stats, player_stats = extract_stats(driver, link, match_id)\n",
    "        \n",
    "        \n",
    "        stats = add_match_id(stats, match_id)\n",
    "        player_stats = add_match_id(player_stats, match_id)\n",
    "\n",
    "        latest_stats.append(stats)\n",
    "        latest_player_stats.append(player_stats)\n",
    "        latest_feed.append(feed)\n",
    "\n",
    "    latest_stats_df = pd.concat(latest_stats, axis=0, ignore_index=True) if latest_stats else pd.DataFrame(columns=['match_id'])\n",
    "    latest_player_stats_df = pd.concat(latest_player_stats, axis=0, ignore_index=True) if latest_player_stats else pd.DataFrame(columns=['match_id'])\n",
    "    latest_feed_df = pd.concat(latest_feed, axis=0, ignore_index=True) if latest_feed else pd.DataFrame(columns=['match_id'])\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "    return latest_stats_df, latest_player_stats_df, latest_feed_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_team_stats, match_player_stats, match_feeds = extract_match_data(links, driver)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
